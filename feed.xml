<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://andygreenphd.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://andygreenphd.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-12T07:55:45+00:00</updated><id>https://andygreenphd.github.io/feed.xml</id><title type="html">Andrew William Green, Ph.D.</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Is Georgia moving to hand-marked paper ballots for elections?</title><link href="https://andygreenphd.github.io/blog/2025/03/27/is-georgia-moving-to-hand-marked-paper-ballots-for-elections/" rel="alternate" type="text/html" title="Is Georgia moving to hand-marked paper ballots for elections?"/><published>2025-03-27T00:00:00+00:00</published><updated>2025-03-27T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2025/03/27/is-georgia-moving-to-hand-marked-paper-ballots-for-elections</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2025/03/27/is-georgia-moving-to-hand-marked-paper-ballots-for-elections/"><![CDATA[<p>The Georgia Assembly is considering a bill to return the state to hand-marked paper ballots as the default, with touchscreen voting devices available for people with disabilities.</p> <p>The bill won’t make it through the 2025 legislative session as it was not passed by the Senate before crossover day. Hopefully, it will survive the session and be ready for next year.</p> <p>I believe this is a very good move for the state, and I hope it passes next year and is signed into law by the governor. A 2018 National Academies of Sciences, Engineering, and Medicine study recommended the use of hand-marked paper ballots for voting, as did Dr. Wenke Lee, the sole security member of a 2019 Georgia panel created to examine election security.</p> <p>hand-marked paper ballots are the safest and most secure way to ensure that a voter’s intent is counted as intended and provide a clean method for post-election audits (hopefully using the risk-limiting audit method).</p> <p>AJC reporting – <a href="https://www.ajc.com/politics/georgia-lawmakers-propose-switch-to-hand-marked-paper-ballots/WFF4W34YCJEBPNMIEPODCMFGWM/?fbclid=IwZXh0bgNhZW0CMTAAAR0nLbIt23T8h2y7zTCy_-SOTLIZABxbMmsspc3LJRRwz20Z8OZiEux1x5M_aem_3bzzfM47-eKz8LI78tmUeg">https://www.ajc.com/politics/georgia-lawmakers-propose-switch-to-hand-marked-paper-ballots/WFF4W34YCJEBPNMIEPODCMFGWM/?fbclid=IwZXh0bgNhZW0CMTAAAR0nLbIt23T8h2y7zTCy_-SOTLIZABxbMmsspc3LJRRwz20Z8OZiEux1x5M_aem_3bzzfM47-eKz8LI78tmUeg</a></p> <p>Senate Bill 214 text – <a href="https://www.legis.ga.gov/api/legislation/document/20252026/233014?fbclid=IwZXh0bgNhZW0CMTAAAR21Ov5iwZLFeefwyNWpl7o8Qz_o4tICq-Z7uinQ_avlkocS4dYUcc3Kw6U_aem_V2FpMdWycNEFdSkRxUeJCQ">https://www.legis.ga.gov/api/legislation/document/20252026/233014?fbclid=IwZXh0bgNhZW0CMTAAAR21Ov5iwZLFeefwyNWpl7o8Qz_o4tICq-Z7uinQ_avlkocS4dYUcc3Kw6U_aem_V2FpMdWycNEFdSkRxUeJCQ</a></p> <p>2018 National Academies of Sciences, Engineering, and Medicine study on election security – <a href="https://nap.nationalacademies.org/read/25120/chapter/1">https://nap.nationalacademies.org/read/25120/chapter/1</a></p> <p>LinkedIn post from Dr. Wenke Lee on why he supports the use of hand-marked paper ballots – <a href="https://www.linkedin.com/pulse/why-computer-scientists-prefer-paper-ballots-wenke-lee/">https://www.linkedin.com/pulse/why-computer-scientists-prefer-paper-ballots-wenke-lee/</a></p>]]></content><author><name></name></author><category term="Analysis,"/><category term="Legislation"/><summary type="html"><![CDATA[The Georgia Assembly is considering a bill to return the state to hand-marked paper ballots as the default, with touchscreen voting devices available for people with disabilities.]]></summary></entry><entry><title type="html">“What does ChatGPT Know about Information Systems?” accepted for publication at the Communications of the AIS</title><link href="https://andygreenphd.github.io/blog/2025/03/26/what-does-chatgpt-know-about-information-systems-accepted-for-publication-at-the-communications-of-the-ais/" rel="alternate" type="text/html" title="“What does ChatGPT Know about Information Systems?” accepted for publication at the Communications of the AIS"/><published>2025-03-26T00:00:00+00:00</published><updated>2025-03-26T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2025/03/26/what-does-chatgpt-know-about-information-systems-accepted-for-publication-at-the-communications-of-the-ais</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2025/03/26/what-does-chatgpt-know-about-information-systems-accepted-for-publication-at-the-communications-of-the-ais/"><![CDATA[<p>I recently worked on a research project with <a href="https://www.marshall.usc.edu/personnel/daniel-edmund-oleary">Dan O’Leary</a>, <a href="https://robinson.gsu.edu/profile/veda-c-storey/">Veda Storey</a>, <a href="https://www.linkedin.com/in/dr-french/">Aaron French</a>, <a href="https://robinson.gsu.edu/profile/joseph-buckman/">Joseph Buckman</a>, <a href="https://works.bepress.com/cecil-chua/about/">Cecil Chua</a>, <a href="https://www.graceyuangu.com/">Grace Gu</a>, <a href="https://www.slu.edu/business/about/faculty/niederman-fred.php">Fred Niederman</a>, <a href="https://www.marshall.usc.edu/personnel/francis-pereira">Francis Pereira</a>, <a href="https://business.wvu.edu/faculty-and-staff/directory/profile?pid=3499">Gary Templeton</a>, and <a href="https://acis.pamplin.vt.edu/directory/Wallace.html">Linda Wallace</a> that explored how well ChatGPT would do with exam and quiz questions used by faculty in Information Systems (IS) courses. I’m happy to report that our work has been accepted for publication in the Communications of the AIS.</p> <p>The study found that generative AI tools like ChatGPT performed well on actual exams and quizzes in general IS courses, database management, systems analysis and design, project management, and cybersecurity. ChatGPT earned a B average with multiple-choice and true/false questions and an A average on short answer/essay questions.</p> <p>We recommend that academia look at ways to implement AI tools in the classroom so that students can be prepared for their use in the workplace, rather than prohibiting their use. It’s our job to ensure that students are well prepared when they graduate, and AI is just the latest innovation we must incorporate into our teaching.</p> <p>The article is available for download at <a href="https://aisel.aisnet.org/cais/vol56/iss1/19/">https://aisel.aisnet.org/cais/vol56/iss1/19/</a></p>]]></content><author><name></name></author><category term="Academia,"/><category term="Research,"/><category term="Students"/><summary type="html"><![CDATA[I recently worked on a research project with Dan O’Leary, Veda Storey, Aaron French, Joseph Buckman, Cecil Chua, Grace Gu, Fred Niederman, Francis Pereira, Gary Templeton, and Linda Wallace that explored how well ChatGPT would do with exam and quiz questions used by faculty in Information Systems (IS) courses. I’m happy to report that our work has been accepted for publication in the Communications of the AIS.]]></summary></entry><entry><title type="html">“To report or not to report? Extending Protection Motivation Theory to Vulnerability Discovery and Disclosure” accepted for publication at Computers &amp;amp; Security</title><link href="https://andygreenphd.github.io/blog/2024/04/27/to-report-or-not-to-report-extending-protection-motivation-theory-to-vulnerability-discovery-and-disclosure-accepted-for-publication-at-computers-&-security/" rel="alternate" type="text/html" title="“To report or not to report? Extending Protection Motivation Theory to Vulnerability Discovery and Disclosure” accepted for publication at Computers &amp;amp; Security"/><published>2024-04-27T00:00:00+00:00</published><updated>2024-04-27T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2024/04/27/to-report-or-not-to-report-extending-protection-motivation-theory-to-vulnerability-discovery-and-disclosure-accepted-for-publication-at-computers-&amp;-security</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2024/04/27/to-report-or-not-to-report-extending-protection-motivation-theory-to-vulnerability-discovery-and-disclosure-accepted-for-publication-at-computers-&amp;-security/"><![CDATA[<p>I’ve been working with <a href="https://scholar.google.com/citations?hl=en&amp;user=ONmOYEMAAAAJ">Amy Woszczynski</a> and <a href="https://scholar.google.com/citations?hl=en&amp;user=MBkDFTMAAAAJ">DJ Oliver</a> on a study that is near and dear to my heart due to my personal experiences with reporting problems I have discovered. This week, we were informed that our study had been accepted for publication in “Computers &amp; Security,” an A-level journal on the Australian Business Deans Journal list. You can see the study at <a href="https://doi.org/10.1016/j.cose.2024.103880">https://doi.org/10.1016/j.cose.2024.103880</a></p> <p>Vulnerability researchers are a class of people who look for weaknesses in software, hardware, or systems to alert organizations that may be vulnerable to the issues found. Unlike cybercriminals who seek to take advantage of these weaknesses, vulnerability researchers engage in these activities to be helpful.</p> <p>Currently, vulnerability researchers face an uphill struggle when trying to report problems they discover. For example, who does a vulnerability researcher contact at an organization when they find a problem? Reporting is also a risky proposition. There are numerous reported instances of organizations pursuing criminal charges or civil action against researchers, resulting in arrests, indictments, trials, and civil lawsuits.</p> <p>One possible solution to address this issue is for an organization to publish a vulnerability disclosure policy (VDP). A typical VDP will let researchers know what systems are in-scope for examination, who to report findings to, and explicitly state that researchers will not face repercussions from reporting if they follow the VDP. Unfortunately, many organizations either have badly constructed VDPs or don’t have one at all.</p> <p>Given the current climate, our research team wanted to examine the decision-making processes that vulnerability researchers undertake when faced with reporting in both VDP and non-VDP situations. To do this, we extended the Protection Motivation theory (PMT) in a novel context to help us study the problem. PMT has been used in prior security research to help understand how employees respond to fear-based appeals to engage in behaviors the organization wants them to, such as backing up data, having strong passwords, and so forth.</p> <p>In our context, vulnerability researchers do not work for the organization and would not be susceptible to the same types of fear appeals that organizations use on their employees. While employees are generally susceptible to fear-based appeals, we theorized that vulnerability researchers would not be. We created a survey instrument and sent it out to active vulnerability researchers to collect the data we needed to dig into the problem.</p> <p>Our analysis showed that organizations should reduce researchers’ fear perceptions and consider adaptive rewards for researchers in order to encourage reporting. We suggested that organizations could do these things by having a well-written VDP that clearly outlines system scope and reporting processes. Additionally, we suggested that organizations have a clearly written “safe harbor” section in the VDP that clearly outlines good faith reporting and provides assurances that organizations will not seek to have researchers arrested or sued civilly for reporting.</p> <p>This was a fun project, filled with challenges and frustrations along the way. We started work more than a year ago, and it’s nice to finally have it concluded and landed at a top-level journal. I’m especially grateful to have been a part of this team. Amy is a trusted mentor and longtime research partner, and I’m fortunate to be able to learn from her. I’ve known DJ since his time in our Ph.D. program at KSU, and he’s simply a good person and fun to work with and be around. I couldn’t ask for a better group to work with, and I’m lucky to be part of their team!</p>]]></content><author><name></name></author><category term="Academia,"/><category term="Research"/><summary type="html"><![CDATA[I’ve been working with Amy Woszczynski and DJ Oliver on a study that is near and dear to my heart due to my personal experiences with reporting problems I have discovered. This week, we were informed that our study had been accepted for publication in “Computers &amp; Security,” an A-level journal on the Australian Business Deans Journal list. You can see the study at https://doi.org/10.1016/j.cose.2024.103880]]></summary></entry><entry><title type="html">“Importing OVA into Amazon AWS”</title><link href="https://andygreenphd.github.io/blog/2023/02/10/importing-ova-into-amazon-aws/" rel="alternate" type="text/html" title="“Importing OVA into Amazon AWS”"/><published>2023-02-10T00:00:00+00:00</published><updated>2023-02-10T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2023/02/10/importing-ova-into-amazon-aws</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2023/02/10/importing-ova-into-amazon-aws/"><![CDATA[<p>While working on a project, I needed to be able to import OVAs into my Amazon AWS account for use in various ways.</p> <p>What I discovered is that Amazon’s documentation on this process is rather… dense and confusing. I spent a good amount of time trying to decipher what the documentation was actually telling me to do, but I finally cracked the code.</p> <p>So, I thought I would document my steps here for my own benefit, and hopefully, this will save someone the time and hassle I went through.</p> <p>CAVEAT – This process was successfully tested using an OVA. I do not know how (or if) it will work with a VMDK, OVF, VHD, or other file formats.</p> <hr/> <h2 id="directions">Directions</h2> <ol> <li>Save the import.json file in a directory</li> <li>Import the OVA into an S3 bucket.</li> <li>In the S3 bucket, select the OVA and choose “Copy S3 URI”.</li> <li>Edit the Url value in the import.json file and paste the S3 URL value.</li> <li>Edit the Description value in the import.json file and provide an appropriate description.</li> <li>Open a command prompt and navigate to the directory where you saved the import.json file</li> <li>Run the command <code class="language-plaintext highlighter-rouge">aws ec2 import-image --description "ENTER VALUE HERE" --disk-containers "file://import.json”</code> <ul> <li><code class="language-plaintext highlighter-rouge">description</code> is a text value used to describe the import task.</li> <li><code class="language-plaintext highlighter-rouge">file://</code> points to the location of the saved import.json file. If you did not navigate to the directory where the file is located, you will need to specify the full path here.</li> </ul> </li> <li>The import process will take a few minutes. Use the <code class="language-plaintext highlighter-rouge">aws ec2 describe-import-image-tasks</code> command to monitor import progress</li> <li>Once the import process is complete, verify the image is in the AMI library.</li> <li>Add tags to the AMI as appropriate to help you recall details such as the source of the OVA and any other relevant details.</li> </ol> <hr/> <h2 id="importjson-file">import.json file</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
    {
      "Description": "OVA DESCRIPTION",
      "Format": "ova",
      "Url": "s3://S3BUCKETNAME/FILENAME"
    }
]

</code></pre></div></div> <hr/> <h2 id="references">References</h2> <ul> <li><a href="https://docs.aws.amazon.com/vm-import/latest/userguide/vmimport-image-import.html">https://docs.aws.amazon.com/vm-import/latest/userguide/vmimport-image-import.html</a></li> <li><a href="https://aws.amazon.com/ec2/vm-import/">https://aws.amazon.com/ec2/vm-import/</a></li> <li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html">https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html</a></li> </ul>]]></content><author><name></name></author><category term="Tips,"/><category term="Research"/><summary type="html"><![CDATA[While working on a project, I needed to be able to import OVAs into my Amazon AWS account for use in various ways.]]></summary></entry><entry><title type="html">“Converting VM images to Docker containers”</title><link href="https://andygreenphd.github.io/blog/2022/01/26/converting-vm-images-to-docker-containers/" rel="alternate" type="text/html" title="“Converting VM images to Docker containers”"/><published>2022-01-26T00:00:00+00:00</published><updated>2022-01-26T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2022/01/26/converting-vm-images-to-docker-containers</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2022/01/26/converting-vm-images-to-docker-containers/"><![CDATA[<p>I’m starting to experiment with Docker containers. From a pedagogical perspective, I see lots of opportunities to quickly and easily script environments to support hands-on lab objectives for my students. Being able to create a series of images, push them to a public Docker repo, and then store a Docker compose script in a Github repo for students to access and run as needed just seems like the way to go. Students can choose to run the lab environment locally, or they can stand up a cloud-based VM in AWS, Azure, Digital Ocean, Linode… you get the idea.</p> <p>I have a small library of existing VMs that may be useful, and I’m lazy enough that I don’t want to rebuild them from scratch as containers. I figured there has to be a way to convert VMs on my Win10 system to Docker containers, and there is. However, it is not a simple process and is time-consuming. I am documenting the steps I followed below, in the hopes that it can help someone else down the road, and for me to refer to in the future. A word of caution – I tested this by converting a Linux VM. I have not tested with a Windows VM, but my expectation is that the conversion process will still work.</p> <p>These instructions were pieced together from the following sources:</p> <ul> <li><a href="https://www.vinnie.work/blog/2021-03-19-virtualmachine-to-docker/">https://www.vinnie.work/blog/2021-03-19-virtualmachine-to-docker/</a></li> <li><a href="https://dannyda.com/2020/06/25/how-to-use-qemu-img-command-to-convert-between-vmdk-raw-qcow2-vdi-vhd-vhdx-formats-disk-images-qemu-img-create-snapshot-resize-etc/">https://dannyda.com/2020/06/25/how-to-use-qemu-img-command-to-convert-between-vmdk-raw-qcow2-vdi-vhd-vhdx-formats-disk-images-qemu-img-create-snapshot-resize-etc/</a></li> <li><a href="https://www.unixmen.com/run-kali-linux-2-0-in-docker-container/">https://www.unixmen.com/run-kali-linux-2-0-in-docker-container/</a></li> </ul> <p>My current environment is a Win10 Enterprise System with WSL and Ubuntu app installed.</p> <ul> <li>Open your Ubuntu app and jump into root by typing <code class="language-plaintext highlighter-rouge">su root</code></li> <li>Fully update Ubuntu by typing <code class="language-plaintext highlighter-rouge">apt-get update &amp;&amp; apt-get upgrade</code></li> <li>We will use qemu-img to convert the existing VM VDMK file to a RAW file for Docker use. Install qemu-img by typing <code class="language-plaintext highlighter-rouge">apt-get install qemu-utils</code> and accept all prompts</li> <li>Ubuntu automatically maps the Windows C partition for access. My VMs are in separate folders in the Windows partition located in c:\agreen\VMs To access that folder, I typed <code class="language-plaintext highlighter-rouge">cd /mnt/c/agreen\VMs</code> (NOTE: you will need to use the directory name on your system where you have your VMs stored)</li> <li>Next, you need to convert your existing VMDK to a raw file for further use. Prior to beginning the conversion process, I created a directory named container under the specific VM folder of the image I’m converting. I’ll use this folder to hold my conversion work product.</li> <li>Now you’re ready to convert the VMDK to a raw file. The syntax is <code class="language-plaintext highlighter-rouge">qemu-img convert -O raw &lt;source VMDK file&gt; &lt;destination&gt;</code>. In my case, I typed <code class="language-plaintext highlighter-rouge">qemu-img convert-O raw image.vdmk container/image.raw</code> (WARNING – This conversion process can take a while, depending on VMDK size)</li> <li>Once the conversion process is complete, you need to look at the partition table on the new RAW file in order to get details necessary to mount the file for further use. I typed <code class="language-plaintext highlighter-rouge">parted -s container/image.raw unit b print</code> to get the data I needed in order to mount the partition. Below is my output – yours may vary. The important thing to pick up is the value in the “Start” column for the boot sector. In my case, it was <strong>1045876</strong></li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-parted-480.webp 480w,/assets/img/2022-01-26-parted-800.webp 800w,/assets/img/2022-01-26-parted-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-parted.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Sample output from the parted command </div> <ul> <li>Next, I had to mount the partition for use. I created a mount point by <code class="language-plaintext highlighter-rouge">typing mkdir /mnt/container</code></li> <li>Next, I mounted the RAW file by typing <code class="language-plaintext highlighter-rouge">mount -o loop,ro,offset=1045876 container/image.raw /mnt/container</code></li> <li>Next, I verified a successful mount by typing <code class="language-plaintext highlighter-rouge">ls /mnt/container</code></li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-ls-output-480.webp 480w,/assets/img/2022-01-26-ls-output-800.webp 800w,/assets/img/2022-01-26-ls-output-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-ls-output.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Sample output from the ls command </div> <ul> <li>Now that we have access to the file system of the VM, we need to put the entire partition in a tarball. I did this by typing <code class="language-plaintext highlighter-rouge">tar -C /mnt/container -czf image.tar.gz container/.</code> (WARNING – this may take a while, depending on partition size)</li> <li>Now that we have the tarball, it’s time to import it into Docker. Ensure Docker is running on your system, then open a PowerShell terminal in Administrator mode and navigate to the container folder that has the tarball. The syntax to import the tarball into Docker is <code class="language-plaintext highlighter-rouge">docker import &lt;filename&gt; &lt;repository&gt;:&lt;tag&gt;</code>. In my case, I typed <code class="language-plaintext highlighter-rouge">docker import image.tar.gz demotest:1.0</code> (WARNING – this may take a while, depending on tarball size)</li> <li>Once the import process completes, type <code class="language-plaintext highlighter-rouge">docker images</code> to get details on your new Docker image that you’ll need to launch a new container.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-docker-images-480.webp 480w,/assets/img/2022-01-26-docker-images-800.webp 800w,/assets/img/2022-01-26-docker-images-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-docker-images.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Sample output from the docker images command </div> <ul> <li>Now you can start a new container from your docker image by typing <code class="language-plaintext highlighter-rouge">docker run -i -t &lt;image id&gt; &lt;commands&gt;</code>. Since this is a Linux-based image, I needed to launch the bash shell on startup. In my case, I typed <code class="language-plaintext highlighter-rouge">docker run -i -t 891dcfcad752 /bin/bash</code></li> <li>Success! My container is now up and running, and I can move around as needed within the environment.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-directory-480.webp 480w,/assets/img/2022-01-26-directory-800.webp 800w,/assets/img/2022-01-26-directory-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-directory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Directory listing from inside my container </div> <p>You can also look at the state of the image and container by using Docker Desktop:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-docker-desktop-480.webp 480w,/assets/img/2022-01-26-docker-desktop-800.webp 800w,/assets/img/2022-01-26-docker-desktop-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-docker-desktop.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Output from the "Images" tab inside Docker Desktop </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-docker-desktop-container-480.webp 480w,/assets/img/2022-01-26-docker-desktop-container-800.webp 800w,/assets/img/2022-01-26-docker-desktop-container-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-docker-desktop-container.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Output from the “Containers/Apps” tab inside Docker Desktop showing a running container </div> <p>You can stop the container inside Docker Desktop by hovering over the container name and clicking the “stop” button, or you can use the <code class="language-plaintext highlighter-rouge">docker stop &lt;container_name&gt;</code> command. In my case, I typed <code class="language-plaintext highlighter-rouge">docker stop xenodochial_darwin</code></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-docker-stop-480.webp 480w,/assets/img/2022-01-26-docker-stop-800.webp 800w,/assets/img/2022-01-26-docker-stop-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-docker-stop.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Output from docker stop command </div> <p>The output of the container name after running the command is confirmation that the container has stopped running. You can also verify the container’s state in Docker Desktop as well.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2022-01-26-docker-container-stopped-480.webp 480w,/assets/img/2022-01-26-docker-container-stopped-800.webp 800w,/assets/img/2022-01-26-docker-container-stopped-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2022-01-26-docker-container-stopped.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Output from the “Containers/Apps” tab inside Docker Desktop showing a stopped container </div> <p>That’s it! We now have a VM image converted into a fully functional Docker container.</p>]]></content><author><name></name></author><category term="Research"/><summary type="html"><![CDATA[I’m starting to experiment with Docker containers. From a pedagogical perspective, I see lots of opportunities to quickly and easily script environments to support hands-on lab objectives for my students. Being able to create a series of images, push them to a public Docker repo, and then store a Docker compose script in a Github repo for students to access and run as needed just seems like the way to go. Students can choose to run the lab environment locally, or they can stand up a cloud-based VM in AWS, Azure, Digital Ocean, Linode… you get the idea.]]></summary></entry><entry><title type="html">“A quick analysis of Georgia HB 134 and HB 156”</title><link href="https://andygreenphd.github.io/blog/2021/04/28/a-quick-analysis-of-georgia-hb-134-and-hb-156/" rel="alternate" type="text/html" title="“A quick analysis of Georgia HB 134 and HB 156”"/><published>2021-04-28T00:00:00+00:00</published><updated>2021-04-28T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2021/04/28/a-quick-analysis-of-georgia-hb-134-and-hb-156</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2021/04/28/a-quick-analysis-of-georgia-hb-134-and-hb-156/"><![CDATA[<p>During the 2021 legislative session, the Georgia Assembly passed two bills related to cybersecurity that warrant some discussion and analysis.</p> <hr/> <p>HB 134 (<a href="https://www.legis.ga.gov/legislation/59005">https://www.legis.ga.gov/legislation/59005</a>) is sitting on Governor Kemp’s desk and has not yet been signed into law. The bill is designed to carve out exemptions from open meeting requirements and public records requests related to cybersecurity contracting and planning. Specifically, HB 134 amends subsection (b) of Chapter 14 of Title 50 of the Official Code of Georgia Annotated (OCGA) (Code SEction 50-14-3) by adding a new section 5, which reads as follows:</p> <blockquote> <p><em>Meetings when discussing or deliberating upon cybersecurity plans, procedures, and contracts regarding the provision of cybersecurity services. No vote in executive session to enter into a cybersecurity contract shall be binding on an agency until a subsequent vote is taken in an open meeting where the identity of the contractor and the terms of the agreement that are not subject to paragraph (25) of subsection (a) of Code Section 50-18-72 are disclosed before the vote.</em></p> </blockquote> <p>Additionally, HB 134 amends subparagraph (A) of paragraph (25) of subsection (a) of Article 4 of Chapter 18 of Title 50 of the OCGA by adding a new section v, which reads as follows:</p> <blockquote> <p><em>Any document or plan for protection relating to the existence, nature, location, or function of cybersecurity devices, programs, or systems designed to protect computer, information technology, or communication systems against terrorist or other attacks that depend for their effectiveness in whole or in part upon a lack of general public knowledge;</em></p> </blockquote> <p>Striking an appropriate balance between a citizen’s right to know and the government taking prudent steps to protect computing infrastructure is a difficult exercise on the best of days. No reasonable person will argue that the government does not have a compelling interest in keeping certain operational aspects of their operations away from public eyes. It appears that this bill is an attempt to do just that.</p> <p>Unfortunately, in my analysis of the language present in this bill and considering the behavior of local governments in the aftermath of recent cybersecurity incidents (namely the City of Atlanta ransomware attack and the SolarWinds breach), this bill swings too far in the direction of keeping details from citizens and would allow government officials to effectively keep all cybersecurity-related details from public examination and citizen overview.</p> <p>I believe Governor Kemp should veto this bill, and that he should ask the Georgia Assembly to send him a bill that uses more tailored, nuanced language that would greatly narrow the size of the exemption being asked for. This bill as currently written is simply too vague and easily abused by governments as an excuse to avoid talking about cybersecurity-related matters completely.</p> <hr/> <p>Governor Kemp signed HB 156 (<a href="https://www.legis.ga.gov/legislation/59069">https://www.legis.ga.gov/legislation/59069</a>) into law on March 25th and went into immediate effect.</p> <p>HB 156 added two new code sections to the OCGA (38-3-22.2 and 38-3-22.3), but it’s section 38-3-22-2 that is problematic. This new code section requires government agencies and utilities to:</p> <blockquote> <p><em>report to the director of emergency management and homeland security, or his or her designee, any cyber attack incident, data breach, or identified use of malware on an agency or computer or network determined by the director to be the type of cyber attack, data breach, or use of malware to create a life-safety event, substantially impact the security of data and information systems, or affect critical systems, equipment, or service delivery.</em></p> </blockquote> <p>So far, so good. This language is similar to efforts on the federal level and is appropriately tailored to be effective without broad overreach.</p> <p>Unfortunately, section (d) exempts any reports or records created in response to this code section from disclosure:</p> <blockquote> <p><em>Any reports or records produced pursuant to this Code section shall not be subject to public inspection or disclosure under Article 4 of Chapter 18 of Title 50.</em></p> </blockquote> <p>I have the same concerns about the public examination and citizen overview here as I did above. Unfortunately, this is already law in the state of Georgia, so the only path forward is to work with legislators to craft legislation in the next session to address these concerns.</p>]]></content><author><name></name></author><category term="Analysis,"/><category term="Legislation"/><summary type="html"><![CDATA[During the 2021 legislative session, the Georgia Assembly passed two bills related to cybersecurity that warrant some discussion and analysis.]]></summary></entry><entry><title type="html">“Quick thoughts about the SolarWinds breach”</title><link href="https://andygreenphd.github.io/blog/2020/12/15/quick-thoughts-about-the-solarwinds-breach/" rel="alternate" type="text/html" title="“Quick thoughts about the SolarWinds breach”"/><published>2020-12-15T00:00:00+00:00</published><updated>2020-12-15T00:00:00+00:00</updated><id>https://andygreenphd.github.io/blog/2020/12/15/quick-thoughts-about-the-solarwinds-breach</id><content type="html" xml:base="https://andygreenphd.github.io/blog/2020/12/15/quick-thoughts-about-the-solarwinds-breach/"><![CDATA[<p>Over the weekend, SolarWinds announced a significant breach. SolarWinds is a suite of tools that allows firms to manage and monitor their systems and networks. SolarWinds says it provides services to:</p> <p>More than 425 of the US Fortune 500</p> <ul> <li>All ten of the top ten US telecommunications companies</li> <li>All five branches of the US Military</li> <li>The US Pentagon, State Department, NASA, NSA, Postal Service, NOAA, Department of Justice, US Secret Service, the Federal Reserve Bank, US Department of Defense, US CDC, and the Office of the President of the United States</li> <li>All five of the top five US accounting firms</li> <li>Hundreds of universities and colleges worldwide</li> </ul> <p>FireEye discovered evidence of the SolarWinds breach while investigating its own recent breach. FireEye is a SolarWinds client and notified them along with law enforcement once they ascertained the nature of the breach.</p> <p>In simple terms, attackers used a “supply chain” attack to place their malware within one of the support files SolarWinds pushes out to customers as part of its overall patching and updating process for their software. Attackers were able to access SolarWinds’ code repository, add the malware to it, and just wait for the software to get pushed out to SolarWinds customers everywhere. Even worse, because the attackers were able to add their malware directly to SolarWinds’ existing code base, the malware was digitally “signed,” which is a means of ensuring authenticity. So, the software was implicitly trusted by all customers as they installed SolarWinds updates on their networks.</p> <p>The attackers designed the malware to stay silent for two weeks post-installation. After that quiet period, the malware would contact a command-and-control (C2) server to receive instructions. The malware had the potential to download and install software, profile the system it was running on, reboot the host system, and disable system services. Because attackers embedded the malware within SolarWinds itself, the malicious traffic masqueraded as legitimate activity associated with a trusted application. In short, the malware operated in plain sight and under the cover of a trusted application. Once the attackers were able to gain a foothold in the victim’s network, they were able to engage in traditional activities to target other systems in the victim network, exfiltrate data, and establish a persistent foothold in the network for long-term activity.</p> <p>The potential scope of this breach is breathtaking, based on the partial client list above. On Sunday evening, the United States Cybersecurity and Infrastructure Agency (CISA) issued Emergency Directive 22-01 regarding the SolarWinds breach. That directive instructed all federal agencies under its purview to:</p> <ul> <li>forensically image all systems running known compromised versions of SolarWinds Orion and analyze for new system or user accounts</li> <li>analyze network traffic to look for indicators of compromise (IoC)</li> <li>immediately disconnect any system running known compromised versions of SolarWinds Orion, and keep them offline pending further CISA guidance</li> </ul> <p>We are very early in this incident. We know that based on the partial customer list above, the potential for the size and scope of this breach is breathtaking. All firms running this software must assume they’ve been breached at this point and take appropriate action. Even though the CISA directive applies only to some federal agencies, it is trustworthy guidance that all firms running known compromised versions of the SolarWinds Orion software should follow. However, dealing with SolarWinds Orion is only one part of the problem. Firms must also take steps to determine whether an attacker has created a persistent “backdoor” foothold in their network and then take appropriate steps to remove it as soon as possible.</p> <p>At this point, “we don’t know what we don’t know.” But one thing is sure – there are many incident response personnel working to assess the damage to their networks and systems, and we won’t know for a while (if ever) the extent of the actual damage.</p>]]></content><author><name></name></author><category term="Analysis"/><summary type="html"><![CDATA[Over the weekend, SolarWinds announced a significant breach. SolarWinds is a suite of tools that allows firms to manage and monitor their systems and networks. SolarWinds says it provides services to:]]></summary></entry></feed>